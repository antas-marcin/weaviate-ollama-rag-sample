---
services:
  weaviate:
    command:
    - --host
    - 0.0.0.0
    - --port
    - '8080'
    - --scheme
    - http
    - --write-timeout=600s
    - --read-timeout=600s
    image: cr.weaviate.io/semitechnologies/weaviate:1.27.0
    ports:
    - 8080:8080
    - 50051:50051
    volumes:
    - ./.docker_data/weaviate:/var/lib/weaviate
    restart: on-failure:0
    environment:
      TRANSFORMERS_INFERENCE_API: 'http://t2v-transformers-baai-bge-m3-onnx:8080'
      QUERY_DEFAULTS_LIMIT: 25
      AUTHENTICATION_ANONYMOUS_ACCESS_ENABLED: 'true'
      PERSISTENCE_DATA_PATH: '/var/lib/weaviate'
      CLUSTER_HOSTNAME: 'weaviate-0'
      DEFAULT_VECTORIZER_MODULE: 'none'
      MODULES_CLIENT_TIMEOUT: '120s'
      ENABLE_MODULES: 'text2vec-ollama,text2vec-transformers,generative-ollama'
  t2v-transformers-baai-bge-m3-onnx:
    image: cr.weaviate.io/semitechnologies/transformers-inference:baai-bge-m3-onnx
  t2v-transformers-mixedbread-ai-mxbai-embed:
    image: cr.weaviate.io/semitechnologies/transformers-inference:mixedbread-ai-mxbai-embed-large-v1-onnx
  generative-ollama:
    image: ollama/ollama:0.3.14
    container_name: generative-ollama
    volumes:
    - ./.docker_data/generative_ollama:/root/.ollama
...